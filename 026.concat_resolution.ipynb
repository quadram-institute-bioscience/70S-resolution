{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 026 change in resolution for concatenation\n",
    "* uses taxonomic information from GTDB (see 005.generate_gtdb_sheet.ipynb)\n",
    "* in a nutshell, our refseq seqs are curated by (1) checkM (done by GTDB), (2) by having annotated rRNAs, and (3) by having a 'complete' 16S rRNA as given by primer presence.\n",
    "* this notebook creates the data sets (alignments and trees), while notebook 028.monophyly_scores.ipynb calculates scores and plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from Bio import Seq, SeqIO, Align, AlignIO, Phylo, Alphabet, pairwise2 \n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import AlignInfo, Applications\n",
    "from Bio.Phylo import draw, TreeConstruction # TreeConstruction.DistanceTreeConstructor \n",
    "# https://bioinformatics.stackexchange.com/questions/4337/ \\\n",
    "#biopython-phylogenetic-tree-replace-branch-tip-labels-by-sequence-logos\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import manifold, metrics, cluster, neighbors, decomposition, preprocessing\n",
    "import skbio, parasail, dendropy, pandas\n",
    "import sys, gzip, re, glob, pickle, collections, subprocess, os, errno, random, itertools\n",
    "\n",
    "def print_redblack(textr, textbb=\"\", textbl=\"\"):\n",
    "    print ('\\x1b[0;1;31;1m'+ str(textr) + '\\x1b[0;1;30;1m'+ str(textbb) + '\\x1b[0;0;30;0m'+ str(textbl) + '\\x1b[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some global variables\n",
    "- first  cell: where to save output, list of _arbitrarily_ chosen genera (as well as list with all genera if you want to change it), RNA gene names\n",
    "- second cell: how to generate species names from table, and how to subsample species (every sequence from well-represented species is sampled with probability inversely proportional to its representativity, s.t. we create an upper bound). We don't want to have > 200 samples from one species and 3 from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the set of possibilities (that we previously downloaded from refseq) \n",
    "all_genera = [\"Campylobacter\",\"Enterococcus\",\"Klebsiella\",\"Listeria\",\"Neisseria\",\"Staphylococcus\",\n",
    "                 \"Vibrio\",\"Clostridium\",\"Escherichia\",\"Helicobacter\",\"Leptospira\",\"Mycobacterium\",\n",
    "                 \"Pseudomonas\",\"Salmonella\",\"Streptococcus\"] ## we don't use this variable in practice\n",
    "# and these below were _arbitrarily_ chosen, based on representativity (i.e. we excluded smaller sets like Lepto, Helico, \n",
    "# Clostridium, Vibrio). But you are free to try different combinations \n",
    "chosen_genera = [\"Klebsiella\",\"Enterococcus\",\"Escherichia\", \"Pseudomonas\", \"Staphylococcus\", \"Streptococcus\"]\n",
    "#chosen_genera = [\"Escherichia\", \"Pseudomonas\", \"Staphylococcus\", \"Streptococcus\"]\n",
    "\n",
    "outdir = \"./026_results/\"\n",
    "rrna_types = [\"16S\", \"23S\", \"5S\"];\n",
    "hyper_types = [\"16Sv1v2\", \"16Sv3v4\"];\n",
    "iupac_dna = {''.join(sorted(v)):k for k,v in Seq.IUPAC.IUPACData.ambiguous_dna_values.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species_list_from_binomial (binomial_str):\n",
    "    return binomial_str.split()[:2]  ## two first names, since might have strain, serovar\n",
    "\n",
    "## this function will generate leaf names on trees (default, below, is GTDB _ accession_number)\n",
    "def species_name_from_binomial (binomial_str, accession_str=None):\n",
    "    binstr = \".\".join(binomial_str.split()[:2]) ## join with \\. since \\_ is already used bt GTDB\n",
    "    if (accession_str):\n",
    "        accession_str = str(re.search('GCF_(\\d+)\\.', accession_str).group(1)) # gets number inside GCF_ddd.1\n",
    "        binstr += \".\" + accession_str\n",
    "    return binstr\n",
    "\n",
    "def subsample_accept_genus (sp_name, list_of_genera = chosen_genera):\n",
    "    for x in list_of_genera:\n",
    "        if x in sp_name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def subsample_accept_counter (sp_name, collection_counter):\n",
    "    if sp_name not in collection_counter:\n",
    "        return False\n",
    "    x = collection_counter[sp_name]\n",
    "    if x < 4:  ## with one or two samples, our scores don't make much sense \n",
    "        return False\n",
    "    if x > 32:\n",
    "        return np.random.random() < 32/x\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read table with files and taxonomic classification\n",
    "- This table was generated in R with notebook [005.generate_gtdb_sheet.ipynb](./005.generate_gtdb_sheet.ipynb) and contains taxonomies (SILVA, NCBI, and GTDB) for all valid genome files that we downloaded. (By 'valid' we mean those passing the quality checks of GTDB.)\n",
    "- In cell below, we add first column as file name, so e.g. `gtdb_taxonomy` is `table[2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31;1mheader: <file>  \u001b[0;1;30;1m['gtdb_taxonomy', 'lsu_silva_23s_taxonomy', 'ncbi_organism_name', 'ncbi_taxonomy', 'ssu_silva_taxonomy']\u001b[0;0;30;0m\u001b[0m\n",
      "first element of list:  ['GCF_000465235.1', 'Campylobacter_D coli', 'Campylobacter coli CVM N29710', 'Campylobacter coli CVM N29710', 'Campylobacter coli', 'Campylobacter jejuni 30318'] \n",
      "\n",
      "first element, with file location:  ['/media/deolivl/QIB_deolivl/bigdata/Campylobacter/GCF_000465235.1_ASM46523v1_genomic.gbff.gz', 'GCF_000465235.1', 'Campylobacter_D coli', 'Campylobacter coli CVM N29710', 'Campylobacter coli CVM N29710', 'Campylobacter coli', 'Campylobacter jejuni 30318']\n"
     ]
    }
   ],
   "source": [
    "gbff_dir = \"/media/deolivl/QIB_deolivl/bigdata/\"   ## directory (or directories, in our case) with refseq genomes\n",
    "#gbff_dir = \"./bigdata/\"\n",
    "\n",
    "file_lines = [line.strip() for line in open(\"./bigdata/gtdb_list.csv\", 'r')]\n",
    "print_redblack(\"header: <file>  \", file_lines[0].split(';')[1:]) ## first column is data.frame index from R\n",
    "\n",
    "table_filenames_species = [line.split(';')[1:] for line in file_lines[1:]] ## skip first line, with headers\n",
    "print (\"first element of list: \", table_filenames_species[0], \"\\n\")\n",
    "\n",
    "fnames = glob.glob(gbff_dir + \"*/GCF_*.gbff.gz\")\n",
    "idx=[i for j in table_filenames_species for i,fname in enumerate(fnames) if j[0] in fname] ## j[1] has accession \n",
    "table_filenames_species = [[fnames[idx[i]]] + j for i,j in enumerate(table_filenames_species)]\n",
    "print (\"first element, with file location: \", table_filenames_species[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomly choose samples from database\n",
    "- subsample based on species representativity, i.e. species w/ more than 40 are downsampled (resulting with at most ~40 samples for each species)\n",
    "- also limit to a few genera (_arbitrarily_ selected)\n",
    "- result is stored in a table that contains both the file path, and several taxonomic inferences (from GTDB spreadsheet)\n",
    "\n",
    "'species' follows the GTDB classification, BTW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31;1mFull set of genera in GTDB:\u001b[0;1;30;1m\u001b[0;0;30;0m{'Clostridium', 'Neisseria_B', 'Clostridium_H', 'Salmonella', 'Clostridium_AM', 'Eubacterium_I', 'Enterococcus_B', 'Helicobacter_G', 'Pseudomonas_F', 'Campylobacter_A', 'Helicobacter_H', 'Leptospira', 'Campylobacter', 'Campylobacter_D', 'Mycobacterium', 'Neisseria', 'Mycolicibacterium', 'Helicobacter_E', 'Mycobacteroides', 'UBA11063', 'Klebsiella_B', 'Clostridium_G', 'Ruminiclostridium_A', 'Clostridium_S', 'Vibrio', 'Klebsiella', 'Clostridium_W', 'Leptospira_A', 'Neisseria_D', 'Enterococcus', 'Helicobacter_A', 'Staphylococcus_A', 'Enterococcus_E', 'Escherichia', 'Clostridium_I', 'Clostridium_J', 'Klebsiella_A', 'Cedecea', 'Listeria', 'Pseudomonas_D', 'Helicobacter_C', 'Clostridium_B', 'Pseudomonas_A', 'Enterococcus_D', 'Helicobacter', 'Pseudomonas_E', 'Clostridium_F', 'Clostridium_AD', 'Helicobacter_F', 'Streptococcus', 'Campylobacter_B', 'Clostridium_K', 'Clostridium_AN', 'Pseudomonas', 'Helicobacter_D', 'Staphylococcus', 'Pseudomonas_B', 'Clostridium_P', 'Bergeriella'}\u001b[0m\n",
      "\u001b[0;1;31;1m\n",
      "Most common species in selected genera (from all samples: \u001b[0;1;30;1m\u001b[0;0;30;0m[('Escherichia flexneri', 372), ('Staphylococcus aureus', 260), ('Klebsiella pneumoniae', 222), ('Pseudomonas aeruginosa', 122), ('Streptococcus pyogenes', 112), ('Escherichia coli', 95), ('Escherichia dysenteriae', 53), ('Streptococcus agalactiae', 50), ('Enterococcus_B faecium', 48), ('Streptococcus pneumoniae', 46)]\u001b[0m\n",
      "\u001b[0;1;31;1m\n",
      "Final set with 697 samples \u001b[0;1;30;1m(51 species) \u001b[0;0;30;0mCounter({'Klebsiella pneumoniae': 39, 'Streptococcus pyogenes': 37, 'Escherichia flexneri': 35, 'Streptococcus pneumoniae': 35, 'Enterococcus_B faecium': 33, 'Escherichia coli_D': 33, 'Escherichia coli': 33, 'Streptococcus agalactiae': 33, 'Escherichia dysenteriae': 31, 'Staphylococcus aureus': 31, 'Streptococcus suis': 31, 'Pseudomonas aeruginosa': 30, 'Streptococcus thermophilus': 23, 'Enterococcus faecalis': 17, 'Klebsiella_A michiganensis': 16, 'Pseudomonas_E avellanae': 13, 'Klebsiella_B aerogenes': 11, 'Klebsiella variicola': 11, 'Pseudomonas_E hunanensis': 11, 'Klebsiella quasipneumoniae': 10, 'Staphylococcus epidermidis': 10, 'Staphylococcus lugdunensis': 10, 'Streptococcus salivarius': 9, 'Streptococcus dysgalactiae': 9, 'Streptococcus equi': 9, 'Streptococcus mutans': 8, 'Escherichia albertii': 7, 'Pseudomonas_E ficuserectae': 7, 'Staphylococcus simulans': 7, 'Streptococcus gordonii': 7, 'Pseudomonas_E monteilii_B': 6, 'Staphylococcus saprophyticus': 6, 'Streptococcus sobrinus': 6, 'Streptococcus intermedius': 6, 'Klebsiella_A oxytoca': 5, 'Pseudomonas_A stutzeri': 5, 'Pseudomonas_E syringae_M': 5, 'Pseudomonas_E protegens': 5, 'Pseudomonas_E piscium': 5, 'Staphylococcus haemolyticus': 5, 'Staphylococcus schleiferi': 5, 'Staphylococcus pseudintermedius': 5, 'Streptococcus gallolyticus': 5, 'Pseudomonas aeruginosa_A': 4, 'Staphylococcus xylosus': 4, 'Staphylococcus equorum_B': 4, 'Streptococcus sanguinis': 4, 'Streptococcus anginosus': 4, 'Streptococcus iniae': 4, 'Streptococcus uberis': 4, 'Streptococcus lutetiensis': 4})\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print_redblack (\"Full set of genera in GTDB:\", \"\", set([x[2].split()[0] for x  in table_filenames_species]))\n",
    "tbl_fl_sp = list(table_filenames_species)\n",
    "# remove all samples that don't belong to set of _arbitrarily_ chosen genera\n",
    "tbl_fl_sp = [x  for x in tbl_fl_sp if subsample_accept_genus (x[2])] \n",
    "species_counter = collections.Counter([x[2] for x in tbl_fl_sp if \"sp.\" not in x[2]]) ## remove generic \"sp.\"\n",
    "print_redblack (\"\\nMost common species in selected genera (from all samples: \", \"\", species_counter.most_common(10))\n",
    "\n",
    "tbl_fl_sp = [x  for x in table_filenames_species if subsample_accept_counter (x[2], species_counter)]\n",
    "\n",
    "tmp_counter = collections.Counter([x[2] for x in tbl_fl_sp])\n",
    "print_redblack(\"\\nFinal set with \" + str(len(tbl_fl_sp)) + \" samples \", \"(\" + str(len(tmp_counter))+ \" species) \",tmp_counter)\n",
    "random.shuffle(tbl_fl_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions \n",
    "- how to extract hypervariable regions from 16S: we use Smith-Waterman to find established primers, for v1v2 and v3v4:\n",
    ">We used the primer pair 27 F/338 R (27 F: 5′-AGAGTTTGATCCTGGCTCAG-3′/ 338 R: 5′-TGCTGCCTCCCGTAGGAGT-3′) to amplify the >V1/V2 region, and the primer pair V3F/V4R (V3F: 5′-CCTACGGGAGGCAGCAG-3′/ V4R: 5′-GGACTACHVGGGTWTCTAAT-3′) for the V3/V4 >hypervariable region from the same sample. <https://www.nature.com/articles/s41598-018-27757-8>\n",
    "\n",
    "Therefore the two reverse ones are: `ACTCCTACGGGAGGCAGCA` and `ATTAGAWACCCBDGTAGTCC`. We use the locations relative to a reference, if the local alignment search fails (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076185 for V1V2 location, for instance). In some cases we can find the second primer only (i.e. beginning of 16S is missing), in which case we use it to predict the first one.\n",
    "\n",
    "The downstream analysis may decide to remove such samples altogether, and here we provide also a check to see if we have 'proper' hypervar segments. Rule-of-thumb is that segment length $l$ should fall within $200<l<500$. The rationale is that some refseq genomes have annotation issues that are picked up by absence of primers or overly large 16S. We are being conservative and excluding such samples from the analysis. BTW the \"primers\" may not be an exact match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_types = [\"16Sv1v2\", \"16Sv3v4\"]\n",
    "#start = res.end_query - res.len_query\n",
    "# v1234[] contains primers for v1v2 forward, v1v2 rev complement, v3v4 forward, v3v4 rev complem \n",
    "v1234 = [\"AGAGTTTGATCCTGGCTCAG\",\"ACTCCTACGGGAGGCAGCA\",\"CCTACGGGAGGCAGCAG\",\"ATTAGAWACCCBDGTAGTCC\"];\n",
    "# fallback: use relative position\n",
    "\n",
    "hypervar = np.array([135, 360, 540, 820, 900, 1100, 1240, 1390, 1500]) # last position, including assumed 16S size\n",
    "hypervar = hypervar/hypervar[-1] # fractions, w.r.t sequence length\n",
    "\n",
    "def get_hypervar_16S (sequence, check_valid=False):\n",
    "    seqsize = len(sequence) \n",
    "    n_h = [int(x * seqsize) for x in hypervar[:4]] # fallback \n",
    "    res = [parasail.sw_stats_diag_16(x,sequence,9,1,parasail.blosum30) for x in v1234]\n",
    "\n",
    "    v1 = res[0].end_ref - res[0].end_query # first position of match\n",
    "    v2 = res[1].end_ref + 1 # last position of match is end_ref, which shold be included (thus, +1)\n",
    "    if (v1 < 0):\n",
    "        v1 = 0 \n",
    "    v3 = res[2].end_ref - res[2].end_query # first position of match\n",
    "    v4 = res[3].end_ref + 1 # last position of match is end_ref, which shold be included (thus, +1)\n",
    "    if (v2 - v1 < 100) and (v4 - v3 > 100): ## only v3v4 was found\n",
    "        v1 = 0; v2 = v3 + 20 ## primers have 20 bp of overlap\n",
    "    if (v2 - v1 > 100) and (v4 - v3 < 100): ## only v1v2 was found\n",
    "        v3 = v2 - 20; v4 = v3 + 460 \n",
    "    \n",
    "    if (v2 - v1 < 100): # last resource, use relative position\n",
    "        v1 = 0; v2 = n_h[1]\n",
    "    if (v4 - v3 < 100):\n",
    "        v3 = n_h[1]; v4 = n_h[3] ## start of hypervar v3 and end of v4\n",
    "    if (v4 > seqsize):\n",
    "        v4 = seqsize\n",
    "    \n",
    "    if (check_valid and ((v2-v1 < 200) or (v2-v1 > 500) or (v4-v3 < 200) or (v4-v3 > 600))):\n",
    "        return None\n",
    "    ## print (\"DEBUG:\", v1, v2, v3, v4)\n",
    "    return {\"16Sv1v2\":sequence[v1:v2], \"16Sv3v4\":sequence[v3:v4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions \n",
    "- alignment wrappers, choice of RNA sequence. When there are several copies, we can \n",
    "    1. choose the longest one,\n",
    "    or\n",
    "    2. we can calculate a consensus between all sequences: align them, and then use IUPAC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_seqs_small (unaligned):\n",
    "    \"\"\" muscle alignment using pipes (not files) \"\"\"\n",
    "    cline = Align.Applications.MuscleCommandline(clwstrict=False, fasta=True, diags=True, maxiters=2, maxhours=4.) \n",
    "    child = subprocess.Popen(str(cline), stdin=subprocess.PIPE, stderr=subprocess.PIPE, stdout=subprocess.PIPE, \n",
    "                             universal_newlines=True, shell=(sys.platform!=\"win32\"))\n",
    "\n",
    "    SeqIO.write(unaligned, child.stdin, \"fasta\") # after this muscle is still waiting, so...\n",
    "    child.stdin.close() # ... we must close the handle by hand, which will then make muscle start calculations\n",
    "    aligned = AlignIO.read(child.stdout, \"fasta\")  # read from stdout as a fasta file \n",
    "    child.terminate()\n",
    "    return aligned\n",
    "\n",
    "def align_seqs (sequences=None, maxiters=12, infile=None, outfile=None, mafft = True):\n",
    "    print (\"started aligning...\", flush=True, end=\" \")\n",
    "    if (sequences is None) and (infile is None):\n",
    "        print (\"ERROR: You must give me an alignment object or file\")\n",
    "        return [] ## OTOH if both are present then infile is overwritten with contents of sequences[]\n",
    "    if infile is None:\n",
    "        ifl = \"/tmp/in.fas\"\n",
    "    else:\n",
    "        ifl = infile\n",
    "    if outfile is None:\n",
    "        ofl = \"/tmp/out.fas\"\n",
    "    else:\n",
    "        ofl = outfile\n",
    "    SeqIO.write(sequences, ifl, \"fasta\")\n",
    "    if (mafft is False):\n",
    "        proc_run = subprocess.check_output(\"muscle -in \" + ifl + \" -diags -maxiters \" + str(maxiters) + \" -out \" + ofl,\n",
    "                                       shell=True, universal_newlines=True)\n",
    "    else: # \"--parttree --6merpair\" and 0.123 is to avoid very long alignments\n",
    "        proc_run = subprocess.check_output(\"mafft --ep 0.3 --op 3.0 --auto \" + ifl + \" > \" + ofl,\n",
    "                                       shell=True, universal_newlines=True)\n",
    "      \n",
    "    aligned = AlignIO.read(ofl, \"fasta\")\n",
    "    print (\"Finished\",flush=True)\n",
    "    if infile is None:\n",
    "        os.system(\"rm -f \" + ifl)\n",
    "    if outfile is None:\n",
    "        os.system(\"rm -f \" + ofl)\n",
    "    return aligned\n",
    "\n",
    "def ambiguous_consensus_from_alignment (align):\n",
    "    #summary_align = AlignInfo.SummaryInfo(Align.MultipleSeqAlignment(align))\n",
    "    summary_align = AlignInfo.SummaryInfo(align) # must be aligned sequences\n",
    "    pssm = summary_align.pos_specific_score_matrix()\n",
    "    consensus = []; \n",
    "    for score in pssm: # something like {'A': 0, 'T': 4.0, 'G': 0, 'C': 2.0} for each column\n",
    "        base_present = ''.join(sorted([base for base in \"ACGT\" if score[base] > 0])) ## neglect indels\n",
    "        if (base_present): \n",
    "            consensus.append(iupac_dna[base_present])\n",
    "    return ''.join(consensus)\n",
    "\n",
    "def get_longest_from_dict(rRNA):\n",
    "    longest_dict = {}\n",
    "    for rna in rrna_types:\n",
    "        longest_dict[rna] = str(rRNA[rna][ np.argsort([len(x) for x in rRNA[rna]])[0] ].seq)\n",
    "    return longest_dict\n",
    "\n",
    "def get_consensus_from_dict(rRNA):\n",
    "    consensus_dict = {}\n",
    "    for rna in rrna_types:\n",
    "        consensus_dict[rna] = ambiguous_consensus_from_alignment(align_seqs_small(rRNA[rna]))\n",
    "    return consensus_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RefSeq reading function\n",
    "- receives element from our table (but uses only the sequence name) and returns a dictionary with sequences for every RNA found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rrna_from_genbank_to_dict (table_fs):\n",
    "    gbank = SeqIO.parse(gzip.open(table_fs[0], \"rt\"), \"genbank\")\n",
    "    rRNA = {}\n",
    "    for rna in rrna_types:\n",
    "        rRNA[rna] = []\n",
    "    genome = next(gbank) # no point in iterating over gbank, only this has whole information\n",
    "    for feature in genome.features:\n",
    "        if(feature.type == \"rRNA\"):\n",
    "            try:\n",
    "                feature_name = feature.qualifiers['product'][0].upper()\n",
    "            except KeyError:\n",
    "                print(\"WARNING: no 'product' feature in\" + table_fs[0])\n",
    "            for rna in rrna_types:\n",
    "                if rna in feature_name:\n",
    "                    this_product = rna\n",
    "                    desc = feature.qualifiers['locus_tag'][0]\n",
    "                    seq = feature.extract(genome.seq)\n",
    "                    record = SeqRecord(seq, id=desc)\n",
    "                    rRNA[this_product].append(record)\n",
    "                    break\n",
    "    success = True\n",
    "    for rna in rrna_types:\n",
    "        success = success and rRNA[rna]\n",
    "    if success:\n",
    "        return rRNA\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop, reading through all sequences in table\n",
    "- table is the one produced above, with refseq genome file path and distinct taxonomic classifications\n",
    "- this loop will create:\n",
    "    1. `rna_concat[]` and `rna_consen[]` dictionaries with longest and consensus, respect., sequences from each \"valid\" genomes. the keys of dictionary are 16S, 23S, 5S, 16Sv1v2 etc. \n",
    "    2. new table with \"valid\" genomes only\n",
    "    3. dictionary with statistics, that  will used by Panda to save spreadsheet \n",
    "- \"valid\" genomes are those for which reasonable RNA sequences were found (some are not annotated, some are missing,..), although these genomes were already curated by GTDB\n",
    "- this loops processes 40 genomes/minute (i.e. this cell takes ~20 minutes to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this if you want to reset variables\n",
    "rna_concat = {}\n",
    "rna_consen = {}\n",
    "stats_dict = {}\n",
    "for rna in rrna_types+hyper_types: # must also initalise 'v1v2' and 'v3v4'\n",
    "    rna_concat[rna] = []\n",
    "    rna_consen[rna] = []\n",
    "for rna in rrna_types:\n",
    "    stats_dict[\"Longest \" + rna] = []\n",
    "    stats_dict[\"Consensus \" + rna] = []\n",
    "    stats_dict[\"Copies \" + rna] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 \n",
      "\u001b[0;1;31;1m16S\u001b[0;1;30;1m        \u001b[0;0;30;0m1550.49 32.30 691.00 1110.00 1540.00 1566.00 1569.00\u001b[0m\n",
      "\u001b[0;1;31;1mconsensus\u001b[0;1;30;1m  \u001b[0;0;30;0m1556.21 45.64 691.00 1514.00 1544.00 1567.00 2741.00\u001b[0m\n",
      "\u001b[0;1;31;1m23S\u001b[0;1;30;1m        \u001b[0;0;30;0m2907.99 65.63 691.00 2070.00 2901.00 2930.00 3040.00\u001b[0m\n",
      "\u001b[0;1;31;1mconsensus\u001b[0;1;30;1m  \u001b[0;0;30;0m2923.91 88.67 691.00 2833.00 2902.00 2938.00 5180.00\u001b[0m\n",
      "\u001b[0;1;31;1m5S\u001b[0;1;30;1m        \u001b[0;0;30;0m115.87 0.80 691.00 105.00 115.00 116.00 127.00\u001b[0m\n",
      "\u001b[0;1;31;1mconsensus\u001b[0;1;30;1m  \u001b[0;0;30;0m117.17 32.09 691.00 115.00 115.00 116.00 960.00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "all_fl_sp = []\n",
    "\n",
    "for file_counter, tfs in enumerate(tbl_fl_sp):\n",
    "    if not (file_counter+1)%20:\n",
    "        print (str(file_counter+1), end=\" \", flush=True)\n",
    "    rna_dict = get_rrna_from_genbank_to_dict (tfs)\n",
    "    # (some dict will have no usable features or b/c too long/too short\n",
    "    if rna_dict: # tfs[2] = GTDB, 3=lsuSILVA, 5=NCBI, 6=ssuSILVA\n",
    "        spname = species_name_from_binomial (tfs[2], tfs[1]) # tfs[1] = accession number \n",
    "        \n",
    "        concat_seqs = get_longest_from_dict (rna_dict)\n",
    "        hypervars = get_hypervar_16S(concat_seqs['16S'], check_valid = True)\n",
    "        if (hypervars): ## only considers samples with well-formated hypervar segments\n",
    "            concat_seqs.update(hypervars)\n",
    "            for rna, rseq in concat_seqs.items():\n",
    "                rna_concat[rna].append(SeqRecord(Seq.Seq(rseq,Alphabet.IUPAC.ambiguous_dna),id=spname,description=spname))\n",
    "\n",
    "            consen_seqs = get_consensus_from_dict (rna_dict)\n",
    "            consen_seqs.update(get_hypervar_16S(consen_seqs['16S'])) # adds two elements, with v3v4 and v1v2 regions\n",
    "            for rna, rseq in consen_seqs.items():\n",
    "                rna_consen[rna].append(SeqRecord(Seq.Seq(rseq,Alphabet.IUPAC.ambiguous_dna),id=spname,description=spname))\n",
    "\n",
    "            for rna in rrna_types: # stored into CSV \n",
    "                stats_dict[\"Longest \" + rna].append(len(concat_seqs[rna]))\n",
    "                stats_dict[\"Consensus \" + rna].append(len(consen_seqs[rna]))\n",
    "                stats_dict[\"Copies \" + rna].append(len(rna_dict[rna])) # how many copies\n",
    "            all_fl_sp.append(tfs) # successful elements of tbl_fs_sp    \n",
    "\n",
    "# save table\n",
    "fl=gzip.open(outdir+\"all_fl_sp.pickle.gz\", \"w\"); pickle.dump([all_fl_sp],fl,2); fl.close()\n",
    "\n",
    "print (\"\") # newline\n",
    "for rna in rrna_types:\n",
    "    x = stats_dict[\"Longest \" + rna] \n",
    "    prtnbr = [np.mean(x), np.std(x), len(x), np.min(x), np.percentile(x, 5), np.percentile(x, 95), np.max(x)]\n",
    "    prtstr = \" \".join([\"{0:0.2f}\".format(i) for i in prtnbr])\n",
    "    print_redblack (rna, \"        \", prtstr);\n",
    "    x = stats_dict[\"Consensus \" + rna]\n",
    "    prtnbr = [np.mean(x), np.std(x), len(x), np.min(x), np.percentile(x, 5), np.percentile(x, 95), np.max(x)]\n",
    "    prtstr = \" \".join([\"{0:0.2f}\".format(i) for i in prtnbr])\n",
    "    print_redblack (\"consensus\", \"  \", prtstr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no need to run in general: reading from previous analysis\n",
    "fl=gzip.open(outdir +  \"all_fl_sp.pickle.gz\", \"r\"); [all_fl_sp] = pickle.load(fl); fl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save statistics as CSV spreadsheet\n",
    "- create pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_table_filename_species (table_fs, stats_dictionary):\n",
    "    dfd = {\"Organism (NCBI)\":[], \"Accession Number\":[],\"File Name\":[], \"Species (GTDB)\":[]}\n",
    "    for elem in table_fs: # output at top of notebook has order of elem columns\n",
    "        dfd[\"Accession Number\"].append(elem[1]) \n",
    "        dfd[\"Organism (NCBI)\"].append(elem[4])\n",
    "        dfd[\"File Name\"].append(elem[0].split(\"/\")[-1])\n",
    "        #dfd[\"Species (GTDB)\"].append(\" \".join(elem[3].split(\"_\")))\n",
    "        dfd[\"Species (GTDB)\"].append(elem[2])\n",
    "    for k,v in stats_dictionary.items(): ## append statistics \n",
    "        dfd[k] = v\n",
    "    return pandas.DataFrame(data=dfd)\n",
    "\n",
    "df = create_dataframe_from_table_filename_species (all_fl_sp, stats_dict)\n",
    "df.to_csv(outdir + \"all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align RNA genes independently\n",
    "- that is, each gene or fragment (e.g. 16Sv1v2) is aligned and saved in fasta format to disk\n",
    "- the auxiliary function above is used to call MAFFT (with e=0.123 for similar sequences)\n",
    "- this step usually takes ~5 minutes (for 700 sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n",
      "started aligning... Finished\n"
     ]
    }
   ],
   "source": [
    "# align each of the dictionary values (lists of unaligned seqs)\n",
    "concat_aligned = {k:align_seqs(sequences=v, infile=outdir + k + \"_long.unfas\", outfile=outdir + k + \"_long.fasta\") for k,v in rna_concat.items()}\n",
    "consen_aligned = {k:align_seqs(sequences=v, infile=outdir + k + \"_consensus.unfas\", outfile=outdir + k + \"_consensus.fasta\") for k,v in rna_consen.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions for concatenating alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rna_alignment is a dict with one alignment per rRNA; below the dictionaries have _sequence_ids_ as keys.\n",
    "def add_missing_sequences (align_1, align_2):\n",
    "    seqdict_1 = SeqIO.to_dict(align_1); seqdict_2 = SeqIO.to_dict(align_2)\n",
    "    n1 = align_1.get_alignment_length(); n2 = align_2.get_alignment_length();\n",
    "    for k in seqdict_1:\n",
    "        if k not in seqdict_2:\n",
    "            seqdict_2[k] = SeqRecord(Seq.Seq('N'*n2, Alphabet.IUPAC.ambiguous_dna), id=k, description=k)\n",
    "    for k in seqdict_2:\n",
    "        if k not in seqdict_1:\n",
    "            seqdict_1[k] = SeqRecord(Seq.Seq('N'*n1, Alphabet.IUPAC.ambiguous_dna), id=k, description=k)\n",
    "    return Align.MultipleSeqAlignment(seqdict_1.values()), Align.MultipleSeqAlignment(seqdict_2.values())\n",
    "\n",
    "def create_species_genus_labels (seqlist, have_paralogs = False): \n",
    "    species = ['.'.join(sequence.id.split('.')[:2]) for sequence in seqlist]\n",
    "    genus = [sequence.id.split('.')[0] for sequence in seqlist]\n",
    "    if have_paralogs:# assumes 'genus_species_code_number' names \n",
    "        sample = ['.'.join(sequence.id.split('.')[:3]) for sequence in seqlist]\n",
    "        return species, genus, sample\n",
    "    return species, genus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if resuming from previous analysis, run code below to read genome names table and alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN::  read table\n",
    "concat_aligned = {k:AlignIO.read(outdir + k + \"_long.fasta\", \"fasta\") for k in rrna_types+hyper_types}\n",
    "consen_aligned = {k:AlignIO.read(outdir + k + \"_consensus.fasta\", \"fasta\") for k in rrna_types+hyper_types}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creates list of gene labels in a specific order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./026_results/16Sv1v2', './026_results/16Sv3v4', './026_results/16S', './026_results/23S', './026_results/5S']\n"
     ]
    }
   ],
   "source": [
    "# order of outfile_list is important, since defines order in table, figures\n",
    "outfile_list = [outdir + str(keys) for keys in hyper_types + rrna_types] # 16S etc. but also v1v2 v4\n",
    "print (outfile_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create concatenated alignments\n",
    "- from single-gene alignments, merge two-by-two and also the three of them together (16Sv1v2 etc. alignments are not used, only the full 16S)\n",
    "- if gene is missing, replace it by \"N\" (although this should not happen, since against our definition of \"valid\" genome above, in 'main loop')\n",
    "- we read alignments from disk, merge, and save them to disk. No actual alignment optimisation takes place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Individual rRNAs (already done by align_seqs)\n",
    "for r1, r2 in itertools.combinations(rrna_types,2): # ensure all samples are present\n",
    "    concat_aligned[r1], concat_aligned[r2] = add_missing_sequences(concat_aligned[r1], concat_aligned[r2])\n",
    "    \n",
    "## (2) pairs of rRNAs (16+23, 16+5, 23+5)\n",
    "for r1, r2 in itertools.combinations(rrna_types,2):\n",
    "    outfile_list.append(outdir + str(r1) + str(r2))\n",
    "    for thisalign, suff in zip([concat_aligned, consen_aligned], [\"_long\", \"_consensus\"]):\n",
    "        seq_dict_1 = SeqIO.to_dict(thisalign[r1])\n",
    "        seq_dict_2 = SeqIO.to_dict(thisalign[r2])\n",
    "        tmpalign = [SeqRecord(Seq.Seq(str(seq_dict_1[k].seq) + str(seq_dict_2[k].seq), \n",
    "                                      Alphabet.IUPAC.ambiguous_dna), id=k, description=k) for k in seq_dict_1]\n",
    "        # tmpalign has concat seqs related to _same_ sample (that's why a dictionary and not simply align1+align2)\n",
    "        output_handle = open (outdir + str(r1) + str(r2) + suff + \".fasta\", \"w\")\n",
    "        SeqIO.write(tmpalign, output_handle, \"fasta\")\n",
    "        output_handle.close()\n",
    "\n",
    "## (3) all three concatenated\n",
    "r1, r2, r3 = rrna_types\n",
    "outfile_list.append(outdir + str(r1) + str(r2) + str(r3))\n",
    "\n",
    "for thisalign, suff in zip([concat_aligned, consen_aligned], [\"_long\", \"_consensus\"]):\n",
    "    seq_dict_1 = SeqIO.to_dict(thisalign[r1])\n",
    "    seq_dict_2 = SeqIO.to_dict(thisalign[r2])\n",
    "    seq_dict_3 = SeqIO.to_dict(thisalign[r3])\n",
    "    tmpalign = [SeqRecord(Seq.Seq(str(seq_dict_1[k].seq) + str(seq_dict_2[k].seq) + str(seq_dict_3[k].seq), \n",
    "                                  Alphabet.IUPAC.ambiguous_dna), id=k, description=k) for k in seq_dict_1]\n",
    "    output_handle = open (outdir + str(r1) + str(r2) + str(r3) + suff + \".fasta\", \"w\")\n",
    "    SeqIO.write(tmpalign, output_handle, \"fasta\")\n",
    "    output_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer maximum likelihood trees with iqtree\n",
    "- consensus and long sequences are split in two cells just for convenience, since they may take a while (each inference takes between 10 and 40 minutes)\n",
    "- for testing purposes mainly, we also calculate the UPGMA tree (3rd cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fname in [ofile + suff for suff in [\"_consensus\"] for ofile in outfile_list]:\n",
    "    subprocess.check_output(\"iqtree -s \" + fname + \".fasta -nt 8 -redo -m HKY+G\",shell=True,universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in [ofile + suff for suff in [\"_long\"] for ofile in outfile_list[5:]]:\n",
    "    subprocess.check_output(\"iqtree -s \" + fname + \".fasta -nt 8 -redo -m HKY+G\",shell=True,universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in [ofile + suff for suff in [\"_long\",\"_consensus\"] for ofile in outfile_list]:\n",
    "    subprocess.check_output(\"muscle -maketree -in \" + fname + \".fasta -out \" + fname + \"_upgma.treefile\", shell=True,universal_newlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next step: go to notebook 028.monophyly_scores.ipynb \n",
    "- Now that we have alignments and trees, we proceed to calculate monophyly scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
